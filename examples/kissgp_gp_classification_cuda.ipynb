{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "train_x = Variable(torch.linspace(0, 1, 10001)).cuda()\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (8 * math.pi)))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LatentFunction(gpytorch.GridInducingPointModule):\n",
    "    def __init__(self):\n",
    "        super(LatentFunction, self).__init__(grid_size=30, grid_bounds=[(0, 1)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5,1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "class GPClassificationModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPClassificationModel,self).__init__(BernoulliLikelihood())\n",
    "        self.latent_function = LatentFunction()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.latent_function(x)\n",
    "\n",
    "model = GPClassificationModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_and_predictions(model, plot_train_data=True):\n",
    "    f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    test_x = Variable(torch.linspace(0, 1, 1001)).cuda()\n",
    "    observed_pred = model(test_x)\n",
    "\n",
    "    def ax_plot(ax, rand_var, title):\n",
    "        if plot_train_data:\n",
    "            ax.plot(train_x.data.cpu().numpy(), train_y.data.cpu().numpy(), 'k*')\n",
    "        pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "        ax.plot(test_x.data.cpu().numpy(), pred_labels.data.cpu().numpy(), 'b')\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAADNCAYAAABXc664AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZNKhdliEhECAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7372cd5810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "f = plot_model_and_predictions(model, plot_train_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 135303.047   log_lengthscale: 0.000\n",
      "Iter 2/200 - Loss: 105395.211   log_lengthscale: -0.100\n",
      "Iter 3/200 - Loss: 79291.820   log_lengthscale: -0.197\n",
      "Iter 4/200 - Loss: 59728.645   log_lengthscale: -0.295\n",
      "Iter 5/200 - Loss: 49602.047   log_lengthscale: -0.389\n",
      "Iter 6/200 - Loss: 37766.188   log_lengthscale: -0.486\n",
      "Iter 7/200 - Loss: 33309.281   log_lengthscale: -0.583\n",
      "Iter 8/200 - Loss: 29976.496   log_lengthscale: -0.682\n",
      "Iter 9/200 - Loss: 20820.926   log_lengthscale: -0.782\n",
      "Iter 10/200 - Loss: 16286.612   log_lengthscale: -0.884\n",
      "Iter 11/200 - Loss: 16341.395   log_lengthscale: -0.986\n",
      "Iter 12/200 - Loss: 20888.533   log_lengthscale: -1.089\n",
      "Iter 13/200 - Loss: 16596.367   log_lengthscale: -1.190\n",
      "Iter 14/200 - Loss: 17902.766   log_lengthscale: -1.286\n",
      "Iter 15/200 - Loss: 14620.590   log_lengthscale: -1.383\n",
      "Iter 16/200 - Loss: 12729.295   log_lengthscale: -1.483\n",
      "Iter 17/200 - Loss: 10976.598   log_lengthscale: -1.583\n",
      "Iter 18/200 - Loss: 11625.962   log_lengthscale: -1.682\n",
      "Iter 19/200 - Loss: 9984.485   log_lengthscale: -1.781\n",
      "Iter 20/200 - Loss: 10359.377   log_lengthscale: -1.873\n",
      "Iter 21/200 - Loss: 9397.215   log_lengthscale: -1.961\n",
      "Iter 22/200 - Loss: 8161.364   log_lengthscale: -2.048\n",
      "Iter 23/200 - Loss: 8127.033   log_lengthscale: -2.131\n",
      "Iter 24/200 - Loss: 8647.009   log_lengthscale: -2.205\n",
      "Iter 25/200 - Loss: 7789.338   log_lengthscale: -2.279\n",
      "Iter 26/200 - Loss: 7232.001   log_lengthscale: -2.350\n",
      "Iter 27/200 - Loss: 6968.385   log_lengthscale: -2.418\n",
      "Iter 28/200 - Loss: 7327.539   log_lengthscale: -2.483\n",
      "Iter 29/200 - Loss: 7646.989   log_lengthscale: -2.546\n",
      "Iter 30/200 - Loss: 7433.741   log_lengthscale: -2.606\n",
      "Iter 31/200 - Loss: 7138.311   log_lengthscale: -2.664\n",
      "Iter 32/200 - Loss: 6406.935   log_lengthscale: -2.719\n",
      "Iter 33/200 - Loss: 6190.596   log_lengthscale: -2.773\n",
      "Iter 34/200 - Loss: 5545.037   log_lengthscale: -2.823\n",
      "Iter 35/200 - Loss: 5744.182   log_lengthscale: -2.871\n",
      "Iter 36/200 - Loss: 5064.411   log_lengthscale: -2.916\n",
      "Iter 37/200 - Loss: 4705.742   log_lengthscale: -2.957\n",
      "Iter 38/200 - Loss: 4994.338   log_lengthscale: -2.996\n",
      "Iter 39/200 - Loss: 5572.881   log_lengthscale: -3.033\n",
      "Iter 40/200 - Loss: 4002.667   log_lengthscale: -3.068\n",
      "Iter 41/200 - Loss: 3697.915   log_lengthscale: -3.100\n",
      "Iter 42/200 - Loss: 3517.202   log_lengthscale: -3.131\n",
      "Iter 43/200 - Loss: 3659.786   log_lengthscale: -3.160\n",
      "Iter 44/200 - Loss: 3858.738   log_lengthscale: -3.187\n",
      "Iter 45/200 - Loss: 3570.012   log_lengthscale: -3.213\n",
      "Iter 46/200 - Loss: 4177.463   log_lengthscale: -3.240\n",
      "Iter 47/200 - Loss: 5338.975   log_lengthscale: -3.269\n",
      "Iter 48/200 - Loss: 3231.733   log_lengthscale: -3.306\n",
      "Iter 49/200 - Loss: 2528.565   log_lengthscale: -3.341\n",
      "Iter 50/200 - Loss: 2375.633   log_lengthscale: -3.374\n",
      "Iter 51/200 - Loss: 2382.811   log_lengthscale: -3.404\n",
      "Iter 52/200 - Loss: 2425.494   log_lengthscale: -3.432\n",
      "Iter 53/200 - Loss: 2153.479   log_lengthscale: -3.457\n",
      "Iter 54/200 - Loss: 2154.033   log_lengthscale: -3.481\n",
      "Iter 55/200 - Loss: 1977.702   log_lengthscale: -3.502\n",
      "Iter 56/200 - Loss: 2022.991   log_lengthscale: -3.522\n",
      "Iter 57/200 - Loss: 2114.326   log_lengthscale: -3.540\n",
      "Iter 58/200 - Loss: 1915.669   log_lengthscale: -3.556\n",
      "Iter 59/200 - Loss: 1968.990   log_lengthscale: -3.571\n",
      "Iter 60/200 - Loss: 1813.550   log_lengthscale: -3.585\n",
      "Iter 61/200 - Loss: 1771.803   log_lengthscale: -3.598\n",
      "Iter 62/200 - Loss: 1737.829   log_lengthscale: -3.609\n",
      "Iter 63/200 - Loss: 1524.286   log_lengthscale: -3.620\n",
      "Iter 64/200 - Loss: 1577.767   log_lengthscale: -3.629\n",
      "Iter 65/200 - Loss: 1445.269   log_lengthscale: -3.638\n",
      "Iter 66/200 - Loss: 1513.083   log_lengthscale: -3.646\n",
      "Iter 67/200 - Loss: 1417.513   log_lengthscale: -3.654\n",
      "Iter 68/200 - Loss: 1340.915   log_lengthscale: -3.661\n",
      "Iter 69/200 - Loss: 1427.279   log_lengthscale: -3.667\n",
      "Iter 70/200 - Loss: 1337.333   log_lengthscale: -3.673\n",
      "Iter 71/200 - Loss: 1363.661   log_lengthscale: -3.678\n",
      "Iter 72/200 - Loss: 1323.763   log_lengthscale: -3.683\n",
      "Iter 73/200 - Loss: 1280.974   log_lengthscale: -3.688\n",
      "Iter 74/200 - Loss: 1215.654   log_lengthscale: -3.692\n",
      "Iter 75/200 - Loss: 1270.668   log_lengthscale: -3.697\n",
      "Iter 76/200 - Loss: 1171.597   log_lengthscale: -3.700\n",
      "Iter 77/200 - Loss: 1202.891   log_lengthscale: -3.704\n",
      "Iter 78/200 - Loss: 1149.746   log_lengthscale: -3.708\n",
      "Iter 79/200 - Loss: 1145.308   log_lengthscale: -3.711\n",
      "Iter 80/200 - Loss: 1140.859   log_lengthscale: -3.714\n",
      "Iter 81/200 - Loss: 1097.007   log_lengthscale: -3.717\n",
      "Iter 82/200 - Loss: 1103.714   log_lengthscale: -3.720\n",
      "Iter 83/200 - Loss: 1047.143   log_lengthscale: -3.723\n",
      "Iter 84/200 - Loss: 1060.224   log_lengthscale: -3.726\n",
      "Iter 85/200 - Loss: 1073.495   log_lengthscale: -3.729\n",
      "Iter 86/200 - Loss: 994.102   log_lengthscale: -3.732\n",
      "Iter 87/200 - Loss: 1027.694   log_lengthscale: -3.734\n",
      "Iter 88/200 - Loss: 994.826   log_lengthscale: -3.737\n",
      "Iter 89/200 - Loss: 990.367   log_lengthscale: -3.740\n",
      "Iter 90/200 - Loss: 1001.820   log_lengthscale: -3.743\n",
      "Iter 91/200 - Loss: 1013.773   log_lengthscale: -3.746\n",
      "Iter 92/200 - Loss: 957.751   log_lengthscale: -3.749\n",
      "Iter 93/200 - Loss: 1016.822   log_lengthscale: -3.752\n",
      "Iter 94/200 - Loss: 984.703   log_lengthscale: -3.755\n",
      "Iter 95/200 - Loss: 1014.119   log_lengthscale: -3.759\n",
      "Iter 96/200 - Loss: 1007.001   log_lengthscale: -3.763\n",
      "Iter 97/200 - Loss: 1024.660   log_lengthscale: -3.767\n",
      "Iter 98/200 - Loss: 1026.191   log_lengthscale: -3.772\n",
      "Iter 99/200 - Loss: 1009.394   log_lengthscale: -3.777\n",
      "Iter 100/200 - Loss: 1018.444   log_lengthscale: -3.782\n",
      "Iter 101/200 - Loss: 1024.870   log_lengthscale: -3.788\n",
      "Iter 102/200 - Loss: 1062.021   log_lengthscale: -3.795\n",
      "Iter 103/200 - Loss: 1185.971   log_lengthscale: -3.802\n",
      "Iter 104/200 - Loss: 1180.926   log_lengthscale: -3.811\n",
      "Iter 105/200 - Loss: 1146.815   log_lengthscale: -3.822\n",
      "Iter 106/200 - Loss: 1121.995   log_lengthscale: -3.834\n",
      "Iter 107/200 - Loss: 984.433   log_lengthscale: -3.848\n",
      "Iter 108/200 - Loss: 971.806   log_lengthscale: -3.861\n",
      "Iter 109/200 - Loss: 1042.882   log_lengthscale: -3.874\n",
      "Iter 110/200 - Loss: 1009.056   log_lengthscale: -3.886\n",
      "Iter 111/200 - Loss: 976.369   log_lengthscale: -3.899\n",
      "Iter 112/200 - Loss: 968.923   log_lengthscale: -3.911\n",
      "Iter 113/200 - Loss: 973.155   log_lengthscale: -3.924\n",
      "Iter 114/200 - Loss: 948.584   log_lengthscale: -3.936\n",
      "Iter 115/200 - Loss: 923.675   log_lengthscale: -3.947\n",
      "Iter 116/200 - Loss: 927.286   log_lengthscale: -3.958\n",
      "Iter 117/200 - Loss: 932.704   log_lengthscale: -3.968\n",
      "Iter 118/200 - Loss: 918.464   log_lengthscale: -3.978\n",
      "Iter 119/200 - Loss: 928.554   log_lengthscale: -3.988\n",
      "Iter 120/200 - Loss: 917.981   log_lengthscale: -3.997\n",
      "Iter 121/200 - Loss: 902.233   log_lengthscale: -4.006\n",
      "Iter 122/200 - Loss: 902.474   log_lengthscale: -4.014\n",
      "Iter 123/200 - Loss: 897.563   log_lengthscale: -4.022\n",
      "Iter 124/200 - Loss: 905.951   log_lengthscale: -4.029\n",
      "Iter 125/200 - Loss: 916.461   log_lengthscale: -4.036\n",
      "Iter 126/200 - Loss: 913.852   log_lengthscale: -4.043\n",
      "Iter 127/200 - Loss: 875.076   log_lengthscale: -4.050\n",
      "Iter 128/200 - Loss: 871.494   log_lengthscale: -4.057\n",
      "Iter 129/200 - Loss: 876.363   log_lengthscale: -4.063\n",
      "Iter 130/200 - Loss: 909.120   log_lengthscale: -4.069\n",
      "Iter 131/200 - Loss: 885.521   log_lengthscale: -4.075\n",
      "Iter 132/200 - Loss: 945.562   log_lengthscale: -4.081\n",
      "Iter 133/200 - Loss: 911.344   log_lengthscale: -4.087\n",
      "Iter 134/200 - Loss: 949.363   log_lengthscale: -4.093\n",
      "Iter 135/200 - Loss: 940.373   log_lengthscale: -4.100\n",
      "Iter 136/200 - Loss: 951.736   log_lengthscale: -4.106\n",
      "Iter 137/200 - Loss: 1037.130   log_lengthscale: -4.113\n",
      "Iter 138/200 - Loss: 996.736   log_lengthscale: -4.121\n",
      "Iter 139/200 - Loss: 970.221   log_lengthscale: -4.128\n",
      "Iter 140/200 - Loss: 912.499   log_lengthscale: -4.136\n",
      "Iter 141/200 - Loss: 896.291   log_lengthscale: -4.144\n",
      "Iter 142/200 - Loss: 865.258   log_lengthscale: -4.151\n",
      "Iter 143/200 - Loss: 865.817   log_lengthscale: -4.157\n",
      "Iter 144/200 - Loss: 865.195   log_lengthscale: -4.163\n",
      "Iter 145/200 - Loss: 849.993   log_lengthscale: -4.168\n",
      "Iter 146/200 - Loss: 830.518   log_lengthscale: -4.173\n",
      "Iter 147/200 - Loss: 872.103   log_lengthscale: -4.178\n",
      "Iter 148/200 - Loss: 849.404   log_lengthscale: -4.182\n",
      "Iter 149/200 - Loss: 823.733   log_lengthscale: -4.185\n",
      "Iter 150/200 - Loss: 822.032   log_lengthscale: -4.189\n",
      "Iter 151/200 - Loss: 833.337   log_lengthscale: -4.192\n",
      "Iter 152/200 - Loss: 838.330   log_lengthscale: -4.194\n",
      "Iter 153/200 - Loss: 841.216   log_lengthscale: -4.196\n",
      "Iter 154/200 - Loss: 838.312   log_lengthscale: -4.199\n",
      "Iter 155/200 - Loss: 824.094   log_lengthscale: -4.201\n",
      "Iter 156/200 - Loss: 803.623   log_lengthscale: -4.202\n",
      "Iter 157/200 - Loss: 815.606   log_lengthscale: -4.204\n",
      "Iter 158/200 - Loss: 782.249   log_lengthscale: -4.205\n",
      "Iter 159/200 - Loss: 798.443   log_lengthscale: -4.207\n",
      "Iter 160/200 - Loss: 820.358   log_lengthscale: -4.208\n",
      "Iter 161/200 - Loss: 802.695   log_lengthscale: -4.209\n",
      "Iter 162/200 - Loss: 808.675   log_lengthscale: -4.210\n",
      "Iter 163/200 - Loss: 792.003   log_lengthscale: -4.211\n",
      "Iter 164/200 - Loss: 780.142   log_lengthscale: -4.212\n",
      "Iter 165/200 - Loss: 756.711   log_lengthscale: -4.213\n",
      "Iter 166/200 - Loss: 792.651   log_lengthscale: -4.214\n",
      "Iter 167/200 - Loss: 771.443   log_lengthscale: -4.214\n",
      "Iter 168/200 - Loss: 759.778   log_lengthscale: -4.215\n",
      "Iter 169/200 - Loss: 745.660   log_lengthscale: -4.216\n",
      "Iter 170/200 - Loss: 760.382   log_lengthscale: -4.216\n",
      "Iter 171/200 - Loss: 759.186   log_lengthscale: -4.217\n",
      "Iter 172/200 - Loss: 762.011   log_lengthscale: -4.217\n",
      "Iter 173/200 - Loss: 757.177   log_lengthscale: -4.218\n",
      "Iter 174/200 - Loss: 745.829   log_lengthscale: -4.218\n",
      "Iter 175/200 - Loss: 757.572   log_lengthscale: -4.218\n",
      "Iter 176/200 - Loss: 728.506   log_lengthscale: -4.219\n",
      "Iter 177/200 - Loss: 732.601   log_lengthscale: -4.219\n",
      "Iter 178/200 - Loss: 733.531   log_lengthscale: -4.220\n",
      "Iter 179/200 - Loss: 732.407   log_lengthscale: -4.221\n",
      "Iter 180/200 - Loss: 716.505   log_lengthscale: -4.221\n",
      "Iter 181/200 - Loss: 724.832   log_lengthscale: -4.222\n",
      "Iter 182/200 - Loss: 720.202   log_lengthscale: -4.222\n",
      "Iter 183/200 - Loss: 721.927   log_lengthscale: -4.223\n",
      "Iter 184/200 - Loss: 731.569   log_lengthscale: -4.224\n",
      "Iter 185/200 - Loss: 724.762   log_lengthscale: -4.224\n",
      "Iter 186/200 - Loss: 706.461   log_lengthscale: -4.225\n",
      "Iter 187/200 - Loss: 717.763   log_lengthscale: -4.225\n",
      "Iter 188/200 - Loss: 703.261   log_lengthscale: -4.226\n",
      "Iter 189/200 - Loss: 687.569   log_lengthscale: -4.227\n",
      "Iter 190/200 - Loss: 697.113   log_lengthscale: -4.228\n",
      "Iter 191/200 - Loss: 695.996   log_lengthscale: -4.228\n",
      "Iter 192/200 - Loss: 712.862   log_lengthscale: -4.229\n",
      "Iter 193/200 - Loss: 687.497   log_lengthscale: -4.230\n",
      "Iter 194/200 - Loss: 695.583   log_lengthscale: -4.231\n",
      "Iter 195/200 - Loss: 689.435   log_lengthscale: -4.232\n",
      "Iter 196/200 - Loss: 699.891   log_lengthscale: -4.233\n",
      "Iter 197/200 - Loss: 681.200   log_lengthscale: -4.234\n",
      "Iter 198/200 - Loss: 689.940   log_lengthscale: -4.235\n",
      "Iter 199/200 - Loss: 691.240   log_lengthscale: -4.235\n",
      "Iter 200/200 - Loss: 669.244   log_lengthscale: -4.236\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "optimizer.n_iter = 0\n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(train_x)\n",
    "    loss = -model.marginal_log_likelihood(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.n_iter += 1\n",
    "    print('Iter %d/200 - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "        i + 1, loss.data[0],\n",
    "        model.latent_function.covar_module.base_kernel_module.log_lengthscale.data.squeeze()[0],\n",
    "    ))\n",
    "    optimizer.step()\n",
    "    \n",
    "# Set back to eval mode\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAADNCAYAAABXc664AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73607c4410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plot_model_and_predictions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
